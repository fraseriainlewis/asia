{
  "hash": "84e0dfefd752f67abacf77d9dafcf907",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"neg_bin_tfp_stan\"\noutput: \n  rmarkdown::html_vignette:\n    toc: true\n    toc_depth: 2\n    number_sections: true\nvignette: >\n  %\\VignetteIndexEntry{neg_bin_tfp_stan}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Prepare model inputs\nset.seed(9999)\nlibrary(rstanarm)\ndata(roaches)\nroaches_cp<-roaches # will make manual edits \nroaches_cp$roach1<-roaches_cp$roach1/100;# manual\nroaches_cp$exposure2<-log(roaches_cp$exposure2) # exposure is logged\npy$data<-r_to_py(roaches_cp)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tensorflow_probability import distributions as tfd\ntfb = tfp.bijectors\nimport numpy as np\nimport pandas as pd\nimport time\n\nrows, columns = data.shape\ny_data=tf.convert_to_tensor(data.iloc[:,0], dtype = tf.float32)\nX=tf.convert_to_tensor(data.iloc[:,1:],dtype=tf.float32)\nX=tf.concat([tf.ones([rows,1],dtype=tf.float32), X], axis=1)\n\n# observe lambda*t = a + b + c but want just lambda, i.e. Y=lambda*t so lambda = Y/t\n# log(lambda) = a + b + c  + log(exposure)\n# P(X=x) = lambda^x exp(-lambda)/x!  lambda = lambda2*t\n#\n\nbeta_expos=tf.convert_to_tensor(1.0,dtype=tf.float32) # dummy\n\ndef make_observed_dist(phi, beta_senior,beta_treatment, beta_roach,alpha):\n    \"\"\"Function to create the observed Normal distribution.\"\"\"\n    \n    B=tf.stack([alpha,beta_roach,beta_treatment,beta_senior,beta_expos])\n    #print(B._shape_as_list())\n    logmu=tf.linalg.matvec(X,B)\n\n    phi_expanded = tf.expand_dims(phi, -1)  # (3, 1)\n    mu = tf.math.exp(logmu)\n    #r = tf$expand_dims(1.0, -1L)/ phi_expanded;  # total_count = 5\n    #probs <- r / (r + mu)\n\n    prob = phi_expanded/(phi_expanded+mu)\n    #prob<-(phi_expanded)/(mu+phi_expanded)\n    # Create distribution for observations\n    return(tfd.Independent(\n        #tfd_normal(loc = mu, scale = sigma_expanded),\n        #mu = exp(mu)\n        #phi <- 0.2  # scale/overdispersion\n\n        #r = tf$expand_dims(1.0, -1L)/ sigma_expanded;  # total_count = 5\n        #probs <- r / (r + mu)\n        tfd.NegativeBinomial(total_count = phi_expanded, probs = 1-prob),\n        reinterpreted_batch_ndims = 1\n    ))\n\n## -------- this needs contructed via cat\n# Define the joint distribution without matrix mult\nmodel = tfd.JointDistributionSequentialAutoBatched([\n  tfd.Normal(loc=0., scale=5., name=\"alpha\"),  # # Intercept (alpha)\n  tfd.Normal(loc=0., scale=2.5, name=\"beta_roach\"),  # # Slope (beta_roach1)\n  tfd.Normal(loc=0., scale=2.5, name=\"beta_treatment\"),  # # Intercept (alpha)\n  tfd.Normal(loc=0., scale=2.5, name=\"beta_senior\"),  # # Slope (beta_roach1)\n  tfd.Exponential(rate=1., name=\"phi\"),\n  make_observed_dist\n])\n\ntf.random.set_seed(99990)\n\ndef log_prob_fn(alpha, beta_roach,beta_treatment,beta_senior,phi):\n  \"\"\"Unnormalized target density as a function of states.\"\"\"\n  return model.log_prob((\n      alpha, beta_roach,beta_treatment,beta_senior,phi, y_data))\n\ndef neg_log_prob_fn(pars):\n    alpha=pars[[0]]\n    beta_roach=pars[[1]]\n    beta_treatment=pars[[2]]\n    beta_senior=pars[[3]]\n    phi=pars[[4]]\n    \"\"\"Unnormalized target density as a function of states.\"\"\"\n    return -model.log_prob((\n      alpha, beta_roach,beta_treatment,beta_senior,phi, y_data))\n\n\n#### get starting values by find MLE\nif(True):\n    start = tf.constant([0.1,0.1,0.1,0.1,0.1],dtype = tf.float32)  # Starting point for the search.\n    optim_results = tfp.optimizer.nelder_mead_minimize(neg_log_prob_fn,\n                 initial_vertex=start, func_tolerance=1e-04,max_iterations=1000)\n\n    #print(optim_results.initial_objective_values)\n    #print(optim_results.objective_value)\n    #print(optim_results.position)\n  \n# bijector to map contrained parameters to real\nunconstraining_bijectors = [\n    tfb.Identity(),\n    tfb.Identity(),\n    tfb.Identity(),\n    tfb.Identity(),\n    tfb.Exp()\n]\n\nnum_results=20000\nnum_burnin_steps=10000\n\nsampler = tfp.mcmc.TransformedTransitionKernel(\n    tfp.mcmc.NoUTurnSampler(\n        target_log_prob_fn=log_prob_fn,\n        step_size=tf.cast(0.5, tf.float32)), #tf.cast(0.1, tf.float32)),\n    bijector=unconstraining_bijectors\n    )\n\nadaptive_sampler = tfp.mcmc.DualAveragingStepSizeAdaptation(\n    inner_kernel=sampler,\n    num_adaptation_steps=int(0.8 * num_burnin_steps),\n    target_accept_prob=tf.cast(0.8, tf.float32))\n\nistate = optim_results.position\n\nn_chains=3\ncurrent_state = [tf.expand_dims(tf.repeat(istate[0],repeats=n_chains,axis=-1),axis=-1),\n                 tf.expand_dims(tf.repeat(istate[1],repeats=n_chains,axis=-1),axis=-1),\n                 tf.expand_dims(tf.repeat(istate[2],repeats=n_chains,axis=-1),axis=-1),\n                 tf.expand_dims(tf.repeat(istate[3],repeats=n_chains,axis=-1),axis=-1),\n                 tf.expand_dims(tf.repeat(istate[4],repeats=n_chains,axis=-1),axis=-1)\n                 ]\n\n# Speed up sampling by tracing with `tf.function`.\n@tf.function(autograph=False, jit_compile=True,reduce_retracing=True)\ndef do_sampling():\n  return tfp.mcmc.sample_chain(\n      kernel=adaptive_sampler,\n      current_state=current_state,\n      num_results=num_results,\n      num_burnin_steps=num_burnin_steps,\n      seed= tf.constant([9199, 9999], dtype=tf.int32),\n      trace_fn=None)#lambda current_state, kernel_results: kernel_results)\n\n\nt0 = time.time()\n#samples, kernel_results = do_sampling()\nsamples = do_sampling()\nt1 = time.time()\nprint(\"Inference ran in {:.2f}s.\".format(t1-t0))\n#> Inference ran in 25.51s.\n\nsamples = list(map(lambda x: tf.squeeze(x).numpy(), samples))\nprint(samples)    \n#> [array([[2.987079 , 2.6098182, 2.5677931],\n#>        [2.7483604, 2.886927 , 2.9317207],\n#>        [2.6856432, 2.6786344, 3.1322134],\n#>        ...,\n#>        [3.2533894, 2.801959 , 3.0235026],\n#>        [3.1033385, 3.0212991, 3.3359637],\n#>        [2.9376042, 2.6799467, 3.0788856]], shape=(20000, 3), dtype=float32), array([[1.3236083, 1.3740337, 1.1372954],\n#>        [1.3656137, 1.6774994, 1.1773032],\n#>        [1.5750321, 1.2522798, 1.2792255],\n#>        ...,\n#>        [1.3976835, 1.3620625, 1.4021512],\n#>        [1.4205782, 1.2618387, 1.439176 ],\n#>        [1.4027553, 1.1244894, 1.3615433]], shape=(20000, 3), dtype=float32), array([[-1.0803449 , -0.04994134, -0.6502478 ],\n#>        [-0.78017116, -1.3083422 , -0.68040556],\n#>        [-0.5861852 , -0.8201815 , -0.6553479 ],\n#>        ...,\n#>        [-1.1314462 , -1.2364191 , -1.0025896 ],\n#>        [-1.2382917 , -1.0904466 , -1.3408219 ],\n#>        [-0.76772535, -0.36030054, -1.3073211 ]],\n#>       shape=(20000, 3), dtype=float32), array([[-0.27886984, -0.12817198, -0.05767922],\n#>        [-0.16990772, -0.00638718, -0.1368666 ],\n#>        [-0.22307259, -0.4108208 , -0.6994592 ],\n#>        ...,\n#>        [-0.60789484, -0.06256802, -0.57999694],\n#>        [-0.6803912 , -0.19749126, -0.38116306],\n#>        [-0.55827487, -0.06315253, -0.33170593]],\n#>       shape=(20000, 3), dtype=float32), array([[0.28163257, 0.24762833, 0.25481734],\n#>        [0.24152358, 0.25584832, 0.27553517],\n#>        [0.30509847, 0.26730496, 0.27132562],\n#>        ...,\n#>        [0.2962671 , 0.25178248, 0.29036015],\n#>        [0.24573997, 0.28279573, 0.2581408 ],\n#>        [0.27390787, 0.23220906, 0.29402545]],\n#>       shape=(20000, 3), dtype=float32)]\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples<-py$samples\n## Trace plots for the reciprocal dispersion parameter\n#png(\"precomputed/vg2_plot1.png\")\nphi_m<-samples[[5]] # the fifth parameter in the model, a matrix\npar(mfrow=c(2,2))\nplot(phi_m[,1],type=\"l\",col=\"green\",main=\"Trace plots (all chains)\")\nlines(phi_m[,2],col=\"blue\")\nlines(phi_m[,3],col=\"skyblue\")\nplot(phi_m[,1],type=\"l\",col=\"green\",main=\"Trace plots - chain 1\")\nplot(phi_m[,2],type=\"l\",col=\"blue\",main=\"Trace plots - chain 2\")\nplot(phi_m[,3],type=\"l\",col=\"skyblue\",main=\"Trace plots - chain 3\")\n```\n\n::: {.cell-output-display}\n![](intro_neg_bin_tfp_stan_files/figure-html/stanrun-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#dev.off()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# reloading data as stan does the log(exposure) internally\ndata(roaches)\nroaches$roach1<-roaches$roach1/100;# manual\n\nstan_glm1 <- stan_glm(y ~ roach1 + treatment + senior, offset = log(exposure2),\n                       data = roaches, family = neg_binomial_2,\n                       prior = normal(0, 2.5),\n                       prior_intercept = normal(0, 5),\n                       seed = 12345,\n                       warmup = 10000,      # Number of warmup iterations per chain\n                       iter = 20000,        # Total iterations per chain (warmup + sampling)\n                       thin = 1,\n                       chains = 2)           # Thinning rate)\n#> \n#> SAMPLING FOR MODEL 'count' NOW (CHAIN 1).\n#> Chain 1: \n#> Chain 1: Gradient evaluation took 0.000513 seconds\n#> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 5.13 seconds.\n#> Chain 1: Adjust your expectations accordingly!\n#> Chain 1: \n#> Chain 1: \n#> Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)\n#> Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)\n#> Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)\n#> Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)\n#> Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)\n#> Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)\n#> Chain 1: Iteration: 10001 / 20000 [ 50%]  (Sampling)\n#> Chain 1: Iteration: 12000 / 20000 [ 60%]  (Sampling)\n#> Chain 1: Iteration: 14000 / 20000 [ 70%]  (Sampling)\n#> Chain 1: Iteration: 16000 / 20000 [ 80%]  (Sampling)\n#> Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)\n#> Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)\n#> Chain 1: \n#> Chain 1:  Elapsed Time: 0.731 seconds (Warm-up)\n#> Chain 1:                1.065 seconds (Sampling)\n#> Chain 1:                1.796 seconds (Total)\n#> Chain 1: \n#> \n#> SAMPLING FOR MODEL 'count' NOW (CHAIN 2).\n#> Chain 2: \n#> Chain 2: Gradient evaluation took 1.6e-05 seconds\n#> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\n#> Chain 2: Adjust your expectations accordingly!\n#> Chain 2: \n#> Chain 2: \n#> Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)\n#> Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)\n#> Chain 2: Iteration:  4000 / 20000 [ 20%]  (Warmup)\n#> Chain 2: Iteration:  6000 / 20000 [ 30%]  (Warmup)\n#> Chain 2: Iteration:  8000 / 20000 [ 40%]  (Warmup)\n#> Chain 2: Iteration: 10000 / 20000 [ 50%]  (Warmup)\n#> Chain 2: Iteration: 10001 / 20000 [ 50%]  (Sampling)\n#> Chain 2: Iteration: 12000 / 20000 [ 60%]  (Sampling)\n#> Chain 2: Iteration: 14000 / 20000 [ 70%]  (Sampling)\n#> Chain 2: Iteration: 16000 / 20000 [ 80%]  (Sampling)\n#> Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)\n#> Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)\n#> Chain 2: \n#> Chain 2:  Elapsed Time: 0.732 seconds (Warm-up)\n#> Chain 2:                1.075 seconds (Sampling)\n#> Chain 2:                1.807 seconds (Total)\n#> Chain 2:\nres_m<-as.matrix(stan_glm1)\n\n#png(\"precomputed/vg2_plot2.png\")\npar(mfrow=c(1,1))\nplot(density(c(phi_m)),col=\"skyblue\",lwd=2, main=\"rstanarm (orange) v TF (blue)\",\n        xlab=\"Reciprocal Dispersion\") # all chains combined\nlines(density(res_m[,\"reciprocal_dispersion\"]),col=\"orange\",lwd=2)\n```\n\n::: {.cell-output-display}\n![](intro_neg_bin_tfp_stan_files/figure-html/stanrun1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#dev.off()\n\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nphi_m<-samples[[3]] # the third parameter in the model, a matrix\n#png(\"precomputed/vg2_plot3.png\")\nplot(density(c(phi_m)),col=\"skyblue\",lwd=2, main=\"rstanarm (orange) v TF (blue)\",\nxlab=\"treatment effect\") # all chains combined\nlines(density(res_m[,\"treatment\"]),col=\"orange\",lwd=2)\n```\n\n::: {.cell-output-display}\n![](intro_neg_bin_tfp_stan_files/figure-html/stanrun2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#dev.off()\n```\n:::\n\n\n",
    "supporting": [
      "intro_neg_bin_tfp_stan_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}