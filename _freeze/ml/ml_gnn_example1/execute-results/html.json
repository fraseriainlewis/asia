{
  "hash": "5fd14a6867514700e1cba49cc371b113",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"tf_gnn_example\"\noutput: \n  rmarkdown::html_vignette:\n    toc: true\n    toc_depth: 2\n    number_sections: true\nvignette: >\n  %\\VignetteIndexEntry{tf_gnn_example}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(tfclinical)\nlibrary(ragg)\nlibrary(reticulate)\n#use_virtualenv(\"C://Users//fil44768//OneDrive - GSK//Documents//.virtualenvs//gnn\", required=TRUE)\nuse_virtualenv(\"/Users/work/gnn\", required = TRUE)\n# 1. Set the device to 'png' (which both R and Python understand)\nknitr::opts_chunk$set(dev = \"png\")\n\n# 2. Tell R to use ragg as the default engine for all png devices\noptions(device = function(...) ragg::agg_png(...))\n```\n:::\n\n\n## Graphical Neural Network Model\n\nGraphical Neural Networks are increasingly finding application in drug development beyond their historical major use case of prediction and classification of new potential drug molecules. Newer applications include extending to electronic patient records for prediction of future disease outcomes.\n\nThis example is ported from the [original on Tensorflow GNN github site](https://colab.research.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/intro_mutag_example.ipynb). Unlike other vignettes, a custom Python setup is required here for reticulate so as ensure correct version compatibility of tensorflow and tensorflow-gnn. See installation guide under advanced.\n\nNeeds compatible versions (installed via pip in venv hard coding versions):\n\n-   Python: 3.11.14\n-   Name: tf_keras\n    -   Version: 2.16.0\n-   Name: tensorflow\n    -   Version: 2.16.2\n-   Name: tensorflow-gnn\n    -   Version: 1.0.3\n-   Python: 3.13.1\n-   Name: tf_keras\n    -   Version: 2.20.1\n-   Name: tensorflow\n    -   Version: 2.20.0\n-   Name: tensorflow-gnn\n    -   Version: 1.0.3\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nos.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"  # For TF2.16+.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_gnn as tfgnn\n\n#print(f'Running TF-GNN {tfgnn.__version__} with TensorFlow {tf.__version__}.')\n```\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ntrain_path = os.path.join(os.getcwd(), 'data/mutag', 'train.tfrecords')\nval_path = os.path.join(os.getcwd(), 'data/mutag', 'val.tfrecords')\n#get_ipython().system('ls -l {train_path} {val_path}')\n\nprint(f\" the train path={train_path}\")\n#>  the train path=/Users/work/asia/ml/data/mutag/train.tfrecords\n#exit()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngraph_tensor_spec = tfgnn.GraphTensorSpec.from_piece_specs(\n    context_spec=tfgnn.ContextSpec.from_field_specs(features_spec={\n                  'label': tf.TensorSpec(shape=(1,), dtype=tf.int32)\n    }),\n    node_sets_spec={\n        'atoms':\n            tfgnn.NodeSetSpec.from_field_specs(\n                features_spec={\n                    tfgnn.HIDDEN_STATE:\n                        tf.TensorSpec((None, 7), tf.float32)\n                },\n                sizes_spec=tf.TensorSpec((1,), tf.int32))\n    },\n    edge_sets_spec={\n        'bonds':\n            tfgnn.EdgeSetSpec.from_field_specs(\n                features_spec={\n                    tfgnn.HIDDEN_STATE:\n                        tf.TensorSpec((None, 4), tf.float32)\n                },\n                sizes_spec=tf.TensorSpec((1,), tf.int32),\n                adjacency_spec=tfgnn.AdjacencySpec.from_incident_node_sets(\n                    'atoms', 'atoms'))\n    })\n```\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef decode_fn(record_bytes):\n  graph = tfgnn.parse_single_example(\n      graph_tensor_spec, record_bytes, validate=True)\n\n  # extract label from context and remove from input graph\n  context_features = graph.context.get_features_dict()\n  label = context_features.pop('label')\n  new_graph = graph.replace_features(context=context_features)\n\n  return new_graph, label\n\n\n# In[7]:\n\n\ntrain_ds = tf.data.TFRecordDataset([train_path]).map(decode_fn)\nval_ds = tf.data.TFRecordDataset([val_path]).map(decode_fn)\n\ncount = train_ds.reduce(tf.constant(0), lambda x, _: x + 1)\nprint(f\"number of training record={count}\\n\")\n#> number of training record=150\ncountval = val_ds.reduce(tf.constant(0), lambda x, _: x + 1)\nprint(f\"number of validation record={countval}\\n\")\n#> number of validation record=38\n# ### Look at one example from the dataset\n\n# In[8]:\n\n\ng, y = train_ds.take(1).get_single_element()\n\n\n# #### Node features\n# \n# Node features represent the 1-hot encoding of the atom type (0=C, 1=N, 2=O, 3=F,\n# 4=I, 5=Cl, 6=Br).\n\n# In[9]:\n\n\nprint(f\"g.node_sets['atoms'].features[tfgnn.HIDDEN_STATE]=\\n{g.node_sets['atoms'].features[tfgnn.HIDDEN_STATE]}\")\n#> g.node_sets['atoms'].features[tfgnn.HIDDEN_STATE]=\n#> [[1. 0. 0. 0. 0. 0. 0.]\n#>  [1. 0. 0. 0. 0. 0. 0.]\n#>  [1. 0. 0. 0. 0. 0. 0.]\n#>  [1. 0. 0. 0. 0. 0. 0.]\n#>  [1. 0. 0. 0. 0. 0. 0.]\n#>  [1. 0. 0. 0. 0. 0. 0.]\n#>  [0. 1. 0. 0. 0. 0. 0.]\n#>  [0. 0. 1. 0. 0. 0. 0.]\n#>  [0. 0. 1. 0. 0. 0. 0.]\n#>  [0. 1. 0. 0. 0. 0. 0.]\n#>  [0. 0. 0. 0. 0. 0. 1.]\n#>  [0. 1. 0. 0. 0. 0. 0.]\n#>  [0. 0. 1. 0. 0. 0. 0.]\n#>  [0. 0. 1. 0. 0. 0. 0.]]\n\n\n# #### Bond Edges\n# \n# In this example, we consider the bonds between atoms undirected edges. To encode\n# them in the GraphsTuple, we store the undirected edges as pairs of directed\n# edges in both directions.\n# \n# `adjacency.source` contains the source node indices, and `adjacency.target` contains the corresponding target node indices.\n\n# In[10]:\n\nprint(f\"g.edge_sets['bonds'].adjacency.source=\\n{g.edge_sets['bonds'].adjacency.source}\")\n#> g.edge_sets['bonds'].adjacency.source=\n#> [ 0  0  1  1  1  2  2  3  3  3  4  4  4  5  5  5  6  6  6  7  8  9 10 11\n#>  11 11 12 13]\n\n#g.edge_sets['bonds'].adjacency.source\n\n\n# In[11]:\n\nprint(f\"g.edge_sets['bonds'].adjacency.target=\\n{g.edge_sets['bonds'].adjacency.target}\")\n#> g.edge_sets['bonds'].adjacency.target=\n#> [ 1  5  0  2 11  1  3  2  4 10  3  5  9  0  4  6  5  7  8  6  6  4  3  1\n#>  12 13 11 11]\n#g.edge_sets['bonds'].adjacency.target\n\n\n# #### Edge features\n# \n# Edge features represent the bond type as one-hot encoding.\n\n# In[12]:\n\nprint(f\"g.edge_sets['bonds'].features[tfgnn.HIDDEN_STATE]=\\n{g.edge_sets['bonds'].features[tfgnn.HIDDEN_STATE]}\")\n#> g.edge_sets['bonds'].features[tfgnn.HIDDEN_STATE]=\n#> [[1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [1. 0. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 0. 1. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 0. 1. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 0. 1. 0.]\n#>  [0. 1. 0. 0.]\n#>  [0. 0. 1. 0.]\n#>  [0. 1. 0. 0.]]\n#g.edge_sets['bonds'].features[tfgnn.HIDDEN_STATE]\n\n\n# ### Label\n# The label is binary, indicating the mutagenicity of the molecule. It's either 0 or 1.\n\n# In[13]:\n\n\nprint(f\"\\nthe label={y}\")\n#> \n#> the label=[0]\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#for k, hist in history.history.items():\n#  plt.plot(hist)\n#  plt.title(k)\n#  plt.show()\nfor k, hist in history.history.items():\n    plt.figure()  # Create a new figure for each metric\n    plt.plot(hist)\n    plt.title(k)\n    plt.xlabel('Epoch')\n    plt.ylabel(k)\n    \n    # Save the plot. Using f-strings to name the file based on the key (e.g., loss.png)\n    #plt.savefig(f\"precomputed/pyplot_{k}.png\")\n    \n    # Optional: If you want to show it in the console while running\n    plt.show() \n```\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_gnn_example1_files/figure-html/unnamed-chunk-2-6.png){width=672}\n:::\n\n```{.python .cell-code}\n    \n    #plt.close() \n    \n\n# Feel free to play with the hyperparameters and the model architecture to improve the results!\n```\n:::\n\n\n\n\n## the end\n",
    "supporting": [
      "ml_gnn_example1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}